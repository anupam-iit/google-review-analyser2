# -*- coding: utf-8 -*-
"""greview2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16b2Mc-F42bmwWjxG8zxhaB_x0dEvqPdb
"""

import streamlit as st
import requests
from transformers import pipeline
import plotly.express as px
from bs4 import BeautifulSoup
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from fake_useragent import UserAgent
import pandas as pd

st.set_page_config(page_title="Google Review Sentiment Analyzer", page_icon="üåç")

st.markdown("""
    <h2 style='text-align: center;'>üåç Google Review Sentiment Analyzer</h2>
""", unsafe_allow_html=True)

# Load improved model from HuggingFace
@st.cache_resource
def load_model():
    model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
    return pipeline("sentiment-analysis", model=model_name)

analyzer = load_model()

# Convert model's output to sentiment
def star_to_sentiment(label):
    stars = int(label[0])
    if stars >= 4:
        return "POSITIVE"
    elif stars == 3:
        return "AVERAGE"
    else:
        return "NEGATIVE"

# Input section
st.markdown("### üè¢ Enter Business Info")
business = st.text_input("Business Name (e.g., Jahangirnagar University)")
location = st.text_input("Location (e.g., Dhaka, Bangladesh)")

# Method selection
method = st.radio("Select Review Collection Method:",
                  ["SerpAPI (Limited Free)", "Manual Scraping (More Reviews)", "Google Places API (Free Tier)"])

# Get reviews from SerpAPI
def fetch_reviews_serpapi(business, location):
    SERP_API_KEY = "15aae7e05c594f10ec289cdbbf03a6e116934c8c542e36634c08f6782cb6c56b"
    search_url = "https://serpapi.com/search.json"
    search_params = {
        "engine": "google_maps",
        "q": f"{business} {location}",
        "type": "search",
        "api_key": SERP_API_KEY
    }
    search_res = requests.get(search_url, params=search_params).json()
    try:
        data_id = search_res['local_results'][0]['data_id']
    except:
        return [], "‚ùå Business not found or SerpAPI error."

    review_params = {
        "engine": "google_maps_reviews",
        "data_id": data_id,
        "api_key": SERP_API_KEY
    }
    review_res = requests.get(search_url, params=review_params).json()
    return review_res.get("reviews", []), None

# Get reviews using Selenium (more reviews)
def fetch_reviews_selenium(business, location):
    try:
        from selenium.webdriver.chrome.service import Service
        from webdriver_manager.chrome import ChromeDriverManager
        from selenium.webdriver.chrome.options import Options

        # Configure Selenium options
        options = Options()
        options.add_argument("--headless=new")  # New headless mode
        options.add_argument("--disable-gpu")
        options.add_argument("--no-sandbox")  # Important for Docker/Cloud
        options.add_argument("--disable-dev-shm-usage")  # Important for Docker/Cloud
        ua = UserAgent()
        user_agent = ua.random
        options.add_argument(f'user-agent={user_agent}')
        
        # Use WebDriver Manager to handle chromedriver
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)

        # Search for the business
        search_query = f"{business} {location}".replace(' ', '+')
        driver.get(f"https://www.google.com/maps/search/{search_query}")
        time.sleep(3)

        # Click on the first result
        first_result = driver.find_element(By.CSS_SELECTOR, ".hfpxzc")
        first_result.click()
        time.sleep(3)

        # Scroll to reviews section
        reviews_section = driver.find_element(By.CSS_SELECTOR, "[jsaction='pane.reviewChart.moreReviews']")
        reviews_section.click()
        time.sleep(3)

        # Scroll to load more reviews
        scrollable_div = driver.find_element(By.CSS_SELECTOR, ".m6QErb.DxyBCb.kA9KIf.dS8AEf")

        # Scroll multiple times to load more reviews
        for _ in range(5):
            driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scrollable_div)
            time.sleep(2)

        # Extract reviews
        reviews = []
        review_elements = driver.find_elements(By.CSS_SELECTOR, ".jftiEf")

        for element in review_elements:
            try:
                # Click "More" button to expand text if it exists
                try:
                    more_button = element.find_element(By.CSS_SELECTOR, ".w8nwRe.kyuRq")
                    more_button.click()
                    time.sleep(0.5)
                except:
                    pass

                text = element.find_element(By.CSS_SELECTOR, ".wiI7pd").text
                stars = element.find_element(By.CSS_SELECTOR, ".kvMYJc").get_attribute("aria-label")
                reviews.append({"snippet": text, "stars": stars})
            except Exception as e:
                continue

        driver.quit()
        return reviews, None

    except Exception as e:
        return [], f"‚ùå Error in scraping: {str(e)}"

# Get reviews from Google Places API (free tier)
def fetch_reviews_places_api(business, location):
    PLACES_API_KEY = "YOUR_GOOGLE_PLACES_API_KEY"  # Replace with your actual key
    base_url = "https://maps.googleapis.com/maps/api/place/findplacefromtext/json"

    # First, get the place ID
    params = {
        "input": f"{business} {location}",
        "inputtype": "textquery",
        "fields": "place_id",
        "key": PLACES_API_KEY
    }

    response = requests.get(base_url, params=params)
    data = response.json()

    if not data.get('candidates'):
        return [], "‚ùå Business not found in Google Places API"

    place_id = data['candidates'][0]['place_id']

    # Now get place details including reviews
    details_url = "https://maps.googleapis.com/maps/api/place/details/json"
    details_params = {
        "place_id": place_id,
        "fields": "review",
        "key": PLACES_API_KEY
    }

    details_response = requests.get(details_url, params=details_params)
    details_data = details_response.json()

    if 'result' not in details_data or 'reviews' not in details_data['result']:
        return [], "‚ùå No reviews found for this business"

    return details_data['result']['reviews'], None

# Analyze review sentiment
def analyze_reviews(reviews):
    results = []
    counts = {"POSITIVE": 0, "AVERAGE": 0, "NEGATIVE": 0}

    for r in reviews:
        text = r.get("snippet") or r.get("text", "")
        if not text.strip():
            continue
        prediction = analyzer(text)[0]
        label_raw = prediction['label']  # e.g., "4 stars"
        label = star_to_sentiment(label_raw)
        score = prediction['score']
        results.append({
            "text": text,
            "label": label,
            "stars": label_raw,
            "score": score
        })
        if label in counts:
            counts[label] += 1

    return results, counts

# Main app logic
if st.button("üîç Analyze Reviews"):
    if business and location:
        with st.spinner("Fetching reviews..."):
            if method == "SerpAPI (Limited Free)":
                reviews, error = fetch_reviews_serpapi(business, location)
            elif method == "Manual Scraping (More Reviews)":
                reviews, error = fetch_reviews_selenium(business, location)
            else:  # Google Places API
                reviews, error = fetch_reviews_places_api(business, location)

        if error:
            st.error(error)
        elif not reviews:
            st.warning("‚ö†Ô∏è No reviews found.")
        else:
            with st.spinner("Analyzing sentiments..."):
                results, counts = analyze_reviews(reviews)

            st.success(f"‚úÖ {len(results)} reviews analyzed.")

            # Display summary stats
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Positive Reviews", counts['POSITIVE'])
            with col2:
                st.metric("Average Reviews", counts['AVERAGE'])
            with col3:
                st.metric("Negative Reviews", counts['NEGATIVE'])

            # Pie chart
            labels = ['Positive', 'Average', 'Negative']
            values = [counts['POSITIVE'], counts['AVERAGE'], counts['NEGATIVE']]
            fig = px.pie(
                names=labels,
                values=values,
                color=labels,
                color_discrete_map={'Positive': 'green', 'Average': 'gray', 'Negative': 'red'},
                title="Sentiment Distribution"
            )
            fig.update_traces(textposition='inside', textinfo='percent+label')
            st.plotly_chart(fig, use_container_width=True)

            # Display all reviews in an expandable section
            with st.expander("üìã View All Reviews"):
                for idx, r in enumerate(results, 1):
                    label = "üü¢ Positive" if r["label"] == "POSITIVE" else "üü° Average" if r["label"] == "AVERAGE" else "üî¥ Negative"
                    st.markdown(f"""
                    **Review #{idx}** ({label} | {r['stars']} | Confidence: {r['score']:.2f})
                    {r['text']}
                    """)
                    st.divider()

            # Download option
            df = pd.DataFrame(results)
            csv = df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üì• Download Reviews as CSV",
                data=csv,
                file_name=f"{business}_reviews.csv",
                mime="text/csv"
            )
    else:
        st.warning("Please enter both Business Name and Location.")

st.markdown("---")
st.markdown("""
    <p style='text-align: center; font-size: 13px; color: gray;'>
        Developed by Anupam Roy, A Student of IIT, JU
    </p>
""", unsafe_allow_html=True)
